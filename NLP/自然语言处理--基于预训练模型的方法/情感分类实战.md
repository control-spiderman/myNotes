## 情感分类实战

要完成一个情感分类实战任务，需要编写词表映射、词向量层、融入词向量层的多层感知器数据处理、文本表示、模型训练和测试等辅助功能。

### 词表映射

处理自然语言，首先都需要将输入的语言符号，即token，映射为大于等于0小于词表大小的整数，这个整数也被称为一个token的索引或下标。

```python
from collections import deafultdict
class Vocab:
    def __init__(self, tokens = None):
        self.idx2token = list()
        self.token2idx = dict()
    	if tokens is not None:
            if "<unk>" is not in tokens:
                tokens += "<unk>"
            for token in tokens:
                self.idx2token.append(token)
                self.token2idx[token] = len(self.idx2token) - 1
            self.unk = self.token2idx["<unk>"]
                
	@classmethod
    def build(cls, text, min_freq = 1, reserved_token = None):
        freq_dict = deafultdict(int)
        for sentence in text:
            for token in sentence:
                freq_dict[token] += 1
        uniq_tokens = "<unk>" + (reserved_token if reserved_token else [])
        uniq_tokens += [token for token freq in freq_dict.items() \
                        if freq >= min_freq and token != "<unk>"]
        return cls(uniq_tokens)
    
    def __len__(self):
        return len(self.idx2token)
    def __getitem__(self, token): # 查找输入的token对应的索引值，如果token不存在，默认返回unk的索引值
        return self.token2idx.get(token, self.unk)
    def convert_token2idx(self, tokens): # 查找一系列token的索引值
        return [self[token] for token in tokens] # 调用了__getitem__这个特殊方法
    def convert_idx2token(self,idx): # 查找一系列索引值对应的token
        return [self.idx2token[index] for index in idx]
```

### 词向量层

在使用深度学习进行自然语言处理时，需要将一个token转换为一个低维、稠密、连续的词向量（也称embedding），此处通过调用torch.nn包提供的embedding层即可实现该功能。

创建Embedding对象时需要传入两个参数：num_embedding和embedding_dim，前者是词表的大小，后者是embedding层的维度。

调用该功能是将输入的整数张量（词表映射后的token的索引）中每个整数映射成维度为embedding_dim的张量。实例如下：

```python
embedding = nn.Embedding(8, 3) # 定义词表大小为8，embedding向量维度为3
# 输入形状为（2,4）的整数张量，相当于词表有8个词
input = torch.tensor([[0, 1, 2, 1], [4, 6, 6, 7]], dtype=torch.long)
# 调用embedding对象
output = embedding(input)
print(output.shape)
# 输出张量形状为(2, 4, 3)，即在原来的维度上增加一个长度为3的维
```

### 融入词向量层的多层感知器

将一个映射成词向量的文本，输入到多层感知器中的示例：

```python
import torch.nn
import torch
from torch.nn import functional as F
class MLP(nn.Module):
	def __init__(self, embedding_dim, vocab_size, hidden_size, class_nums):
        super(MLP, self).__init__()
        self.embedding = nn.Embedding(vocab_size, embedding_dim)
        self.linear1 = nn.Linear(embedding_dim, hidden_size)
        self.activate  =F.relu
        self.linear2 = nn.Linear(hidden_size, class_nums)
        
    def forward(self, input):
        embedding = self.embedding(input).mean(dim=1) # 将序列中的多个embedding进行聚合（此处求平均）
        output = self.linear2(self.activate(self.linear1(embedding)))
        # 获取每个序列属于某一类概率的对数值
        probs = F.log_softmax(outputs, dim=1)
        return probs
    
mlp = MLP(embedding_dim=3, vocab_size=8, hidden_size=5, class_nums=2)
# 输入为两个长度为4的整数序列，也就是有两句有4个token的文本
input = torch.tensor([[0, 1, 2, 1], [4, 6, 6, 7]], dtype=torch.long) 
# 模型中把每句中的token(此处是4个)聚合成一个词向量，方便作为模型的输入
output = mlp(input)
print(output.shape) 
#(2,2)
```

> 每个子文本(即输入序列)中都含有多个词向量，将他们表示成多层感知器的输入向量的方法有：
>
> - 直接拼成一个n*d长度的一维向量：这个方法对位置过于敏感，不合适
> - 使用词袋模型（BOW），不考虑序列中各个词的顺序，而是考虑成一个集合

上面两种方法都不太合适，pytorch中提供了一种更灵活的解决方案，即embeddingBag层。它首先将不定长的序列拼接起来，然后用一个偏移量（offset）来记录每个序列的起始位置。使用案例：

### 数据处理

#### 原始数据预处理

数据处理步骤就是先将待处理的数据从硬盘或者其他地方加载到程序中。此时读入的是原始文本，所以需要先做分句、标记解析等预处理过程转换成标记（token）序列，然后使用词表映射工具将每个标记映射到相应的索引值。此处使用NLTK提供的句子倾向性分析数据（sentence_polarity）：

```python
def load_sentence_polarity():
	from nltk.corpus import sentence_polarity
	vocab = Vocab.build(sentence_polarity.sents())
	train_data = [(vocab.convert_token2idx(sentence), 0) for sentence in sentence_polarity.sents(categories='pos')[:4000] + (vocab.convert_token2idx(sentence), 1) for sentence in sentence_polarity.sents(categories='neg')[:4000]]
	test_data = [(vocab.convert_token2idx(sentence), 0) for sentence in sentence_polarity.sents(categories='pos')[4000:] + (vocab.convert_token2idx(sentence), 1) for sentence in sentence_polarity.sents(categories='neg')[4000:]]
	return train_data, test_data, vocab
```

#### pytorch数据定义：DataLoader类

上面的方法是常规的数据导入方法，pytorch中专门提供了DataLoader类（torch.utils.data)包中。通过调用和实现该类的对象，可以方便的实现数据的采样、转换和处理。

```python
from torch.utils import DataLoader
data_loader = DataLoader(dataset, batch_size=64, collate_fn=collate_fn, shuffle=True)
```

> dataset是Dataset类（torch.utils.data）的一个对象，用于存储数据，一般根据具体的需要创建Dataset的子类。例如：
>
> ```python
> class BowDataset(Dataset):
>     def __init__(self, data):
>         # data是原始数据，例如用上面load_sentence_polarity函数返回的训练和测试数据
>         self.data = data
>     def __len__(self):
>         return len(self.data)
>     def __getitem__(self, i):
>         # 返回下标为i的样例
>         return self.data[i]
> ```
>
> collate_fn参数指向一个函数，用于对一个批次的样本进行整理，例如将其转换为张量：
>
> ```python
> def collate_fn(example):
>     # BowDataset中定义了一个样本的数据结构，即输入序列和输出标签的元组
>     # 因此将输入序列（inputs）定义为一个张量的列表，其中每个张量为原始句子中的token序列
> 	inputs = [torch.tensor(ex[0]) for ex in example]
>     # 将输出标签转换为：该批次中全部样例的输出标签（0或1）构成的张量
>     targets = torch.tensor([ex[1] for ex in example], dtype=torch.long)
>     # 获取一个批次中每个阳历的输入序列长度
>     offsets = [0] + [i.shape[0] for i in inputs]
>     # 根据序列长度转换成序列起始位置的偏移量
>     offsets = torch.tensor(offsets[:-1]).cumsun(dim=0)
>     # 将inputs中的张量拼接成一个大的张量
>     inputs = torch.cat(inputs)
>     return inputs, targets, offsets
> ```



### 使用多层感知器模型的训练与测试

对创建的多层感知器模型，使用实际数据进行训练和测试

```python
from torch import nn, optim
from tqdm.auto import tqdm

class MLP(nn.Module):
    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_class):
        super(MLP, self).__init__()
        self.embedding = nn.EmbeddingBag(vocab_size, embedding_dim)
        self.linear1 = nn.Linear(embedding_dim, hidden_dim)
        self.activate = F.relu
        self.linear2 = nn.Linear(hidden_dim, num_class)
    def forward(self, inputs, offsets):
        embedding = self.embedding(inputs, offsets)
        hidden = self.activate(self.linear1(embedding))
        outputs = self.linear2(hidden)
        log_probs = F.log_softmax(outputs, dim=1)
        return log_probs

# 超参数设置
embedding_dim = 128
hidden_dim = 256
num_class = 2
batch_size = 32
num_epoch = 5
# 加载数据
train_data, test_data, vocab = load+_sentence_polarity()
train_dataset = BowDataset(train_data)
test_dataset = BowDataset(test_data)
train_data_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)
test_data_loader = DataLoader(test_dataset, batch_size=1, collate_fn=collate_fn, shuffle=False)
# 加载模型
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = MLP(embedding_dim, len(vocab), hidden_size, class_nums)
model.to(device)
# 训练过程
nll_loss = nn.MLLLoss()
optimizer = optimer.Adam(model.parameters(),lr=0.001)
model.train()
for epoch in range(num_epoch):
    total_loss = 0
    for batch in tqdm(train_data_loader, desc=f"Training Epoch {epoch}"):
        inputs, targets,offsets = [x.to(device) for x in batch]
        log_probs = model(inputs, offsets)
        loss = nll_loss(log_probs, targets)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    print(f"Loss: {total_loss:.2f}")
# 测试过程
acc = 0
for batch in tqdm(test_data_loader, desc=f"Testing"):
    inputs, offsets, targets = [x.to(device) for x in batch]
    with torch.no_grad():
        output = model(inputs, offsets)
        acc += (output.argmax(dim=1) == targets).sum().item()

# 输出在测试集上的准确率
print(f"Acc: {acc / len(test_data_loader):.2f}")
```

